{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import zeta\n",
    "from wordcloud import WordCloud\n",
    "nltk.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_words(path:str):\n",
    "    list_seed_words = []\n",
    "    with open(file=path, mode=\"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            list_seed_words.append(re.sub(\"\\n\", \"\", line))\n",
    "\n",
    "    return list_seed_words\n",
    "\n",
    "def extract_year(date: str):\n",
    "    return date[:4]\n",
    "\n",
    "def list_to_dict_count(lst:list):\n",
    "    out = nltk.defaultdict(int)\n",
    "    for token in lst:\n",
    "        out[token] += 1\n",
    "    return sorted(out.items(), key=lambda x : x[1], reverse=True)\n",
    "\n",
    "def top_n_not_stopwords(d: dict, n=10):\n",
    "    out = nltk.defaultdict(list)\n",
    "    stopwords_english = set(stopwords.words(\"english\"))\n",
    "    sorted_data = dict(sorted(d.items()))\n",
    "    for k, v in sorted_data.items():\n",
    "        for value in v:\n",
    "            if value[0] not in stopwords_english:\n",
    "                out[k].append(value)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azizc\\AppData\\Local\\Temp\\ipykernel_11048\\4241532332.py:2: DtypeWarning: Columns (7,8,10,14,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_igbt = pd.read_csv(\"assign1_data/lgbt_news_corpus.csv\", encoding=\"ISO-8859-1\")\n"
     ]
    }
   ],
   "source": [
    "#load datasets\n",
    "df_igbt = pd.read_csv(\"assign1_data/lgbt_news_corpus.csv\", encoding=\"ISO-8859-1\")\n",
    "df_bg = pd.read_csv(\"assign1_data/background_news_corpus.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Title', 'Id', 'Count', 'Date', 'Category', 'Unnamed: 6',\n",
       "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11',\n",
       "       'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',\n",
       "       'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_igbt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Title', 'Id', 'Count', 'Date', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnamed columns to be able to merge both datasets together later on\n",
    "df_igbt = df_igbt[[\"Text\", \"Title\", \"Id\", \"Count\", \"Date\", \"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Title', 'Id', 'Count', 'Date', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_igbt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both datasets\n",
    "frames = [df_igbt, df_bg]\n",
    "merged_dataset = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Title', 'Id', 'Count', 'Date', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_dataset) == len(df_igbt) + len(df_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
